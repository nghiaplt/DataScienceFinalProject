{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "corpus = [\n",
    "          'Text of the first document.',\n",
    "          'Text of the second document made longer.',\n",
    "          'Number three.',\n",
    "          'This is number four.',\n",
    "]\n",
    "# we need to pass splitted sentences to the model\n",
    "tokenized_sentences = [sentence.split() for sentence in corpus]\n",
    "model = word2vec.Word2Vec(tokenized_sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r', encoding=\"utf8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "            \n",
    "    return words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, word_to_vec_map = read_glove_vecs('./glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12864 entries, 0 to 12863\n",
      "Data columns (total 2 columns):\n",
      "0    12864 non-null object\n",
      "1    12864 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 201.1+ KB\n"
     ]
    }
   ],
   "source": [
    "happy_train = pd.read_csv('./CrawlComment/final_happy.csv', sep='\\t', header=None)\n",
    "angry_train = pd.read_csv('./CrawlComment/final_angry.csv', sep='\\t', header=None)\n",
    "sad_train = pd.read_csv('./CrawlComment/final_sad.csv', sep='\\t', header=None)\n",
    "prank_train = pd.read_csv('./CrawlComment/final_prank.csv', sep='\\t', header=None)\n",
    "frames = [happy_train, angry_train, sad_train, prank_train]\n",
    "\n",
    "df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9004,)\n",
      "(9004,)\n",
      "[1 2 3 0]\n",
      "3    2718\n",
      "0    2397\n",
      "1    2140\n",
      "2    1749\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df[0]\n",
    "y = df[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, shuffle=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train.unique())\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_vec(sentence):\n",
    "    words = sentence.lower().split()\n",
    "    avg = np.zeros((50,0))\n",
    "    total = 0\n",
    "    \n",
    "    for word in words:\n",
    "        try:\n",
    "            vec = word_to_vec_map[word]\n",
    "        except:\n",
    "            print(word)\n",
    "            vec = word_to_vec_map['unk']\n",
    "            \n",
    "        total += vec\n",
    "        \n",
    "    avg = total/len(words)\n",
    "    return avg\n",
    "\n",
    "def check_word(sentence):\n",
    "    words = sentence.lower().split()\n",
    "    \n",
    "    for word in words:\n",
    "        try:\n",
    "            vec = word_to_vec_map[word]\n",
    "        except:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_word('hello my friend cant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (50) into shape (0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-3df33222fd26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mavg_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# avg_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (50) into shape (0)"
     ]
    }
   ],
   "source": [
    "# m = y_train.shape[0]\n",
    "# avg_train = np.zeros((y_train.shape[0], 0))\n",
    "\n",
    "# for i in range(m):\n",
    "#     avg_train[i] = avg_vec(X_train[i])\n",
    "\n",
    "# avg_train\n",
    "\n",
    "# SGD_clf = SGDClassifier(loss='hinge', penalty='l2',\n",
    "#                           alpha=1e-4, random_state=42,\n",
    "#                           max_iter=100, tol=None)\n",
    "# SGD_clf.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
